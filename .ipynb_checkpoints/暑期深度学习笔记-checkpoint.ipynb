{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、神经网络与深度学习\n",
    "\n",
    "## 1 深度学习概论\n",
    "\n",
    "### 1.1 欢迎来到深度学习\n",
    "- AI的意义\n",
    "- 本门课程将要学到的内容\n",
    "\n",
    "### 1.2 神经网络简介\n",
    "常用模型激活函数：ReLU函数\n",
    "神经网络结构：输入 -> 中间层 -> 输出\n",
    "\n",
    "### 1.3 用神经网络进行监督学习\n",
    "- 各AI方面算法规模与性能的比较\n",
    "- 神经网络发展三要素：数据、计算力、算法\n",
    "- 研究过程：Idea -> Code -> Experiment -> Idea -> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 神经网络基础\n",
    "\n",
    "### 2.1 二分类\n",
    "对样本特征进行分析，最终将其分为两类的一类型问题。\n",
    "\n",
    "### 2.2 Logistics Regression\n",
    "给定样本x，求$\\hat{y}=P(y=1|x)$\n",
    "- 输入:$x,长度为n_x$的特征向量\n",
    "- 输出:$\\hat{y}$,回归估计值,介于0与1之间\n",
    "- 参数:$w,b$\n",
    "- 激活函数:sigmoid函数($\\sigma(z)=\\frac{1}{1+e^{-z}}$)\n",
    "\n",
    "$$\\hat{y}=\\sigma(z)$$\n",
    "$$z=wx+b$$\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "### 2.3 梯度下降法的损失函数\n",
    "**损失函数**:$$L(\\hat{y},y)=-(y\\log{\\hat{y}}+(1-y)\\log{(1-\\hat{y})})$$\n",
    "\n",
    "**代价函数**:$$J(w,b)=\\frac{1}{m}\\sum^m_{i=1}{L(\\hat{y},y)}=-\\frac{1}{m}\\sum^m_{i=1}{y^{(i)}\\log{\\hat{y}^{(i)}}+(1-y^{(i)})\\log{(1-\\hat{y}^{(i)})}}$$\n",
    "\n",
    "### 2.4 梯度下降法\n",
    "要找的参数$(w,b)$使得代价函数$J(w,b)$取得最小值,得到这组参数的方法可以使用梯度下降法.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
